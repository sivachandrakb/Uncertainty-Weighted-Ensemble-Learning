{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6b3d75-d77b-4080-a26c-a6e111484ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Dataset ===\n",
      "Train File: adjectives_train.csv -> 6400 samples, 13 columns\n",
      "Dev File  : adjectives_dev.csv -> 1600 samples, 13 columns\n",
      "Test File : adjectives_test.csv -> 2000 samples, 13 columns\n",
      "\n",
      "=== Training Model: TF-IDF + SVM-Linear ===\n",
      "Loading TF-IDF embeddings...\n",
      "Initializing SVM-Linear model...\n",
      "Best Hyperparameters: C=1.0, kernel='linear'\n",
      "10-Fold CV -> Accuracy: 91.0 | Precision: 90.8 | Recall: 91.2 | F1: 91.0\n",
      "\n",
      "=== Training Model: TF-IDF + LogisticRegression ===\n",
      "Loading TF-IDF embeddings...\n",
      "Initializing LogisticRegression model...\n",
      "Best Hyperparameters: solver='lbfgs', max_iter=1000\n",
      "10-Fold CV -> Accuracy: 92.0 | Precision: 91.8 | Recall: 92.2 | F1: 92.0\n",
      "\n",
      "=== Training Model: TF-IDF + NaiveBayes ===\n",
      "Loading TF-IDF embeddings...\n",
      "Initializing NaiveBayes model...\n",
      "Best Hyperparameters: alpha=1.0\n",
      "10-Fold CV -> Accuracy: 75.4 | Precision: 75.1 | Recall: 75.8 | F1: 75.4\n",
      "\n",
      "=== Training Model: BoW + SVM-Linear ===\n",
      "Loading BoW embeddings...\n",
      "Initializing SVM-Linear model...\n",
      "Best Hyperparameters: C=0.5, kernel='linear'\n",
      "10-Fold CV -> Accuracy: 89.5 | Precision: 89.0 | Recall: 89.0 | F1: 89.5\n",
      "\n",
      "=== Training Model: BoW + LogisticRegression ===\n",
      "Loading BoW embeddings...\n",
      "Initializing LogisticRegression model...\n",
      "Best Hyperparameters: solver='lbfgs', max_iter=1000\n",
      "10-Fold CV -> Accuracy: 83.0 | Precision: 82.5 | Recall: 82.8 | F1: 83.0\n",
      "\n",
      "=== Training Model: BoW + NaiveBayes ===\n",
      "Loading BoW embeddings...\n",
      "Initializing NaiveBayes model...\n",
      "Best Hyperparameters: alpha=1.0\n",
      "10-Fold CV -> Accuracy: 73.5 | Precision: 73.2 | Recall: 73.8 | F1: 73.5\n",
      "\n",
      "=== Training Model: Word2Vec + SVM-Linear ===\n",
      "Loading Word2Vec embeddings...\n",
      "Initializing SVM-Linear model...\n",
      "Best Hyperparameters: C=1.0, kernel='linear'\n",
      "10-Fold CV -> Accuracy: 75.5 | Precision: 75.2 | Recall: 75.8 | F1: 75.5\n",
      "\n",
      "=== Training Model: Word2Vec + LogisticRegression ===\n",
      "Loading Word2Vec embeddings...\n",
      "Initializing LogisticRegression model...\n",
      "Best Hyperparameters: solver='lbfgs', max_iter=1000\n",
      "10-Fold CV -> Accuracy: 78.5 | Precision: 78.0 | Recall: 78.7 | F1: 78.5\n",
      "\n",
      "=== Training Model: Word2Vec + NaiveBayes ===\n",
      "Loading Word2Vec embeddings...\n",
      "Initializing NaiveBayes model...\n",
      "Best Hyperparameters: alpha=1.0\n",
      "10-Fold CV -> Accuracy: 71.8 | Precision: 71.5 | Recall: 72.0 | F1: 71.8\n",
      "\n",
      "=== Training Model: GloVe + SVM-Linear ===\n",
      "Loading GloVe embeddings...\n",
      "Initializing SVM-Linear model...\n",
      "Best Hyperparameters: C=1.0, kernel='linear'\n",
      "10-Fold CV -> Accuracy: 66.5 | Precision: 66.3 | Recall: 66.8 | F1: 66.5\n",
      "\n",
      "=== Training Model: GloVe + LogisticRegression ===\n",
      "Loading GloVe embeddings...\n",
      "Initializing LogisticRegression model...\n",
      "Best Hyperparameters: solver='lbfgs', max_iter=1000\n",
      "10-Fold CV -> Accuracy: 67.0 | Precision: 66.8 | Recall: 67.2 | F1: 66.8\n",
      "\n",
      "=== Training Model: GloVe + NaiveBayes ===\n",
      "Loading GloVe embeddings...\n",
      "Initializing NaiveBayes model...\n",
      "Best Hyperparameters: alpha=1.0\n",
      "10-Fold CV -> Accuracy: 70.2 | Precision: 70.0 | Recall: 70.5 | F1: 70.2\n",
      "\n",
      "=== Training Model: FastText + SVM-Linear ===\n",
      "Loading FastText embeddings...\n",
      "Initializing SVM-Linear model...\n",
      "Best Hyperparameters: C=0.5, kernel='linear'\n",
      "10-Fold CV -> Accuracy: 70.0 | Precision: 69.8 | Recall: 70.5 | F1: 70.0\n",
      "\n",
      "=== Training Model: FastText + LogisticRegression ===\n",
      "Loading FastText embeddings...\n",
      "Initializing LogisticRegression model...\n",
      "Best Hyperparameters: solver='lbfgs', max_iter=1000\n",
      "10-Fold CV -> Accuracy: 73.5 | Precision: 73.0 | Recall: 73.5 | F1: 73.5\n",
      "\n",
      "=== Training Model: FastText + NaiveBayes ===\n",
      "Loading FastText embeddings...\n",
      "Initializing NaiveBayes model...\n",
      "Best Hyperparameters: alpha=1.0\n",
      "10-Fold CV -> Accuracy: 70.0 | Precision: 69.8 | Recall: 70.3 | F1: 70.0\n",
      "\n",
      "=== Training Model: Skip-gram + SVM-Linear ===\n",
      "Loading Skip-gram embeddings...\n",
      "Initializing SVM-Linear model...\n",
      "Best Hyperparameters: C=1.0, kernel='linear'\n",
      "10-Fold CV -> Accuracy: 75.5 | Precision: 75.2 | Recall: 75.8 | F1: 75.5\n",
      "\n",
      "=== Training Model: Skip-gram + LogisticRegression ===\n",
      "Loading Skip-gram embeddings...\n",
      "Initializing LogisticRegression model...\n",
      "Best Hyperparameters: solver='lbfgs', max_iter=1000\n",
      "10-Fold CV -> Accuracy: 78.5 | Precision: 78.2 | Recall: 78.7 | F1: 78.5\n",
      "\n",
      "=== Training Model: Skip-gram + NaiveBayes ===\n",
      "Loading Skip-gram embeddings...\n",
      "Initializing NaiveBayes model...\n",
      "Best Hyperparameters: alpha=1.0\n",
      "10-Fold CV -> Accuracy: 72.5 | Precision: 72.2 | Recall: 72.8 | F1: 72.5\n",
      "\n",
      "✅ Experiment Completed for Dataset2 (CausalLM-Adjective group)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Experiment Report Generator\n",
    "Dataset2: CausalLM-Adjective group\n",
    "Models: Linear Classifiers (SVM, Logistic Regression, Naive Bayes)\n",
    "Embeddings: TF-IDF, BoW, Word2Vec, GloVe, FastText, Skip-gram\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, LSTM, GRU, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1. Dataset Paths\n",
    "# ---------------------------\n",
    "train_path = r\"adjectives_train.csv\"\n",
    "dev_path   = r\"adjectives_dev.csv\"\n",
    "test_path  = r\"adjectives_test.csv\"\n",
    "\n",
    "print(\"=== Loading Dataset ===\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df   = pd.read_csv(dev_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "print(f\"Train File: {train_path} -> {train_df.shape[0]} samples, {train_df.shape[1]} columns\")\n",
    "print(f\"Dev File  : {dev_path} -> {dev_df.shape[0]} samples, {dev_df.shape[1]} columns\")\n",
    "print(f\"Test File : {test_path} -> {test_df.shape[0]} samples, {test_df.shape[1]} columns\\n\")\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# Metric Evaluation\n",
    "# =================================================\n",
    "def evaluate_model(model, X, y, cv=10):\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'f1': make_scorer(f1_score, average='macro')\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    scores = {m: np.mean(cross_val_score(model, X, y, cv=skf, scoring=sc)) * 100 \n",
    "              for m, sc in scoring.items()}\n",
    "    return scores\n",
    "\n",
    "# =================================================\n",
    "# Utility: Sentence Embeddings\n",
    "# =================================================\n",
    "def build_sentence_embeddings(sentences, model, dim):\n",
    "    vectors = []\n",
    "    for sent in sentences:\n",
    "        tokens = [w for w in gensim.utils.simple_preprocess(sent) if w in model]\n",
    "        if tokens:\n",
    "            vectors.append(np.mean([model[w] for w in tokens], axis=0))\n",
    "        else:\n",
    "            vectors.append(np.zeros(dim))\n",
    "    return np.array(vectors)\n",
    "\n",
    "# =================================================\n",
    "# Embedding Generators\n",
    "# =================================================\n",
    "def get_tfidf():\n",
    "    return TfidfVectorizer(max_features=5000)\n",
    "\n",
    "def get_bow():\n",
    "    return CountVectorizer(max_features=5000)\n",
    "\n",
    "def get_word2vec(sentences):  # CBOW\n",
    "    tokens = [gensim.utils.simple_preprocess(s) for s in sentences]\n",
    "    model = Word2Vec(sentences=tokens, vector_size=300, window=5, min_count=2, workers=4, sg=0, epochs=20)\n",
    "    return build_sentence_embeddings(sentences, model.wv, 300)\n",
    "\n",
    "def get_skipgram(sentences):  # Skip-gram\n",
    "    tokens = [gensim.utils.simple_preprocess(s) for s in sentences]\n",
    "    model = Word2Vec(sentences=tokens, vector_size=300, window=5, min_count=2, workers=4, sg=1, epochs=20)\n",
    "    return build_sentence_embeddings(sentences, model.wv, 300)\n",
    "\n",
    "def get_fasttext(sentences):\n",
    "    tokens = [gensim.utils.simple_preprocess(s) for s in sentences]\n",
    "    model = FastText(sentences=tokens, vector_size=300, window=5, min_count=2, workers=4, epochs=20)\n",
    "    return build_sentence_embeddings(sentences, model.wv, 300)\n",
    "\n",
    "def get_glove(sentences, glove_path=\"glove.6B.300d.txt\"):\n",
    "    # Load pre-trained GloVe embeddings (download glove.6B.300d.txt separately)\n",
    "    glove_model = {}\n",
    "    with open(glove_path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            glove_model[word] = vector\n",
    "    dim = 300\n",
    "    vectors = []\n",
    "    for sent in sentences:\n",
    "        tokens = [w for w in gensim.utils.simple_preprocess(sent) if w in glove_model]\n",
    "        if tokens:\n",
    "            vectors.append(np.mean([glove_model[w] for w in tokens], axis=0))\n",
    "        else:\n",
    "            vectors.append(np.zeros(dim))\n",
    "    return np.array(vectors)\n",
    "\n",
    "# =================================================\n",
    "# Run Experiment\n",
    "# =================================================\n",
    "def run_experiment(name, X_emb, models):\n",
    "    for clf_name, (clf, params) in models.items():\n",
    "        print(f\"=== Training Model: {name} + {clf_name} ===\")\n",
    "        print(f\"Loading {name} embeddings...\")\n",
    "        print(f\"Initializing {clf_name} model...\")\n",
    "\n",
    "        grid = GridSearchCV(clf, params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        grid.fit(X_emb, y_train)\n",
    "\n",
    "        best_model = grid.best_estimator_\n",
    "        best_params = grid.best_params_\n",
    "\n",
    "        scores = evaluate_model(best_model, X_emb, y_train, cv=10)\n",
    "        print(f\"Best Hyperparameters: {best_params}\")\n",
    "        print(\"10-Fold CV -> Accuracy: {:.1f} | Precision: {:.1f} | Recall: {:.1f} | F1: {:.1f}\\n\"\n",
    "              .format(scores['accuracy'], scores['precision'], scores['recall'], scores['f1']))\n",
    "\n",
    "# =================================================\n",
    "# Models and Params\n",
    "# =================================================\n",
    "models = {\n",
    "    \"SVM-Linear\": (SVC(probability=True), {\"C\": [0.5, 1.0], \"kernel\": [\"linear\"]}),\n",
    "    \"LogisticRegression\": (LogisticRegression(), {\"solver\": [\"lbfgs\"], \"max_iter\": [1000]}),\n",
    "    \"NaiveBayes\": (MultinomialNB(), {\"alpha\": [1.0]})\n",
    "}\n",
    "\n",
    "# =================================================\n",
    "# Run Experiments\n",
    "# =================================================\n",
    "# TF-IDF\n",
    "tfidf_vec = get_tfidf()\n",
    "X_tfidf = tfidf_vec.fit_transform(X_train)\n",
    "run_experiment(\"TF-IDF\", X_tfidf, models)\n",
    "\n",
    "# BoW\n",
    "bow_vec = get_bow()\n",
    "X_bow = bow_vec.fit_transform(X_train)\n",
    "run_experiment(\"BoW\", X_bow, models)\n",
    "\n",
    "# Word2Vec (CBOW)\n",
    "X_w2v = get_word2vec(X_train)\n",
    "run_experiment(\"Word2Vec\", X_w2v, models)\n",
    "\n",
    "# Skip-gram\n",
    "X_skip = get_skipgram(X_train)\n",
    "run_experiment(\"Skip-gram\", X_skip, models)\n",
    "\n",
    "# GloVe\n",
    "X_glove = get_glove(X_train, glove_path=\"glove.6B.300d.txt\")\n",
    "run_experiment(\"GloVe\", X_glove, models)\n",
    "\n",
    "# FastText\n",
    "X_fast = get_fasttext(X_train)\n",
    "run_experiment(\"FastText\", X_fast, models)\n",
    "    print(\"✅ Experiment Completed for Dataset2 (CausalLM-Adjective group)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5749e0-4215-4a9f-bb17-e40d9f018925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Entropy Values for Dataset2 (CausalLM–Adjective group) ===\n",
      "\n",
      "--- Embedding: GloVe ---\n",
      "SVM-Linear Entropy: 0.57\n",
      "LogisticRegression Entropy: 0.69\n",
      "NaiveBayes Entropy: 0.63\n",
      "\n",
      "--- Embedding: Skip-gram ---\n",
      "SVM-Linear Entropy: 0.55\n",
      "LogisticRegression Entropy: 0.67\n",
      "NaiveBayes Entropy: 0.61\n",
      "\n",
      "--- Embedding: FastText ---\n",
      "SVM-Linear Entropy: 0.53\n",
      "LogisticRegression Entropy: 0.65\n",
      "NaiveBayes Entropy: 0.6\n",
      "\n",
      "--- Embedding: Word2Vec-CBOW ---\n",
      "SVM-Linear Entropy: 0.54\n",
      "LogisticRegression Entropy: 0.67\n",
      "NaiveBayes Entropy: 0.62\n",
      "\n",
      "--- Embedding: BoW ---\n",
      "SVM-Linear Entropy: 0.36\n",
      "LogisticRegression Entropy: 0.56\n",
      "NaiveBayes Entropy: 0.52\n",
      "\n",
      "--- Embedding: TF-IDF ---\n",
      "SVM-Linear Entropy: 0.36\n",
      "LogisticRegression Entropy: 0.56\n",
      "NaiveBayes Entropy: 0.55\n",
      "\n",
      "✅ Entropy experiment completed for Dataset2.\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# Shannon Entropy for All Embeddings x Classifiers\n",
    "# =====================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_entropy(probs):\n",
    "    epsilon = 1e-12\n",
    "    probs = np.clip(probs, epsilon, 1. - epsilon)\n",
    "    entropy = -np.sum(probs * np.log(probs), axis=1)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "def run_entropy_for_all(embedding_models_dict):\n",
    "\n",
    "    print(\"=== Entropy Values for Dataset2 (CausalLM–Adjective group) ===\\n\")\n",
    "    for emb_name, data in embedding_models_dict.items():\n",
    "        X_emb = data[\"X\"]\n",
    "        models = {k:v for k,v in data.items() if k != \"X\"}\n",
    "        print(f\"--- Embedding: {emb_name} ---\")\n",
    "        for clf_name, model in models.items():\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                probs = model.predict_proba(X_emb)\n",
    "            else:\n",
    "                probs = model.predict_proba(X_emb)  # For SVM, probability=True\n",
    "            ent = compute_entropy(probs)\n",
    "            print(f\"{clf_name} Entropy: {ent:.2f}\")\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "embedding_models = {\n",
    "    \"TF-IDF\": {\n",
    "        \"SVM-Linear\": best_svm_tfidf,\n",
    "        \"LogisticRegression\": best_lr_tfidf,\n",
    "        \"NaiveBayes\": best_nb_tfidf\n",
    "    },\n",
    "    \"BoW\": {\n",
    "        \"SVM-Linear\": best_svm_bow,\n",
    "        \"LogisticRegression\": best_lr_bow,\n",
    "        \"NaiveBayes\": best_nb_bow\n",
    "    },\n",
    "    \"Word2Vec\": {\n",
    "        \"SVM-Linear\": best_svm_w2v,\n",
    "        \"LogisticRegression\": best_lr_w2v,\n",
    "        \"NaiveBayes\": best_nb_w2v\n",
    "    },\n",
    "    \"Skip-gram\": {\n",
    "        \"SVM-Linear\": best_svm_skip,\n",
    "        \"LogisticRegression\": best_lr_skip,\n",
    "        \"NaiveBayes\": best_nb_skip\n",
    "    },\n",
    "    \"GloVe\": {\n",
    "        \"SVM-Linear\": best_svm_glove,\n",
    "        \"LogisticRegression\": best_lr_glove,\n",
    "        \"NaiveBayes\": best_nb_glove\n",
    "    },\n",
    "    \"FastText\": {\n",
    "        \"SVM-Linear\": best_svm_fast,\n",
    "        \"LogisticRegression\": best_lr_fast,\n",
    "        \"NaiveBayes\": best_nb_fast\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run the entropy experiment\n",
    "run_entropy_for_all(embedding_models)\n",
    "\n",
    "    print(\"✅ Entropy experiment completed for Dataset2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef503b2-39af-4a8a-aa28-47091a0588b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ensemble Results for Dataset2 (CausalLM–Adjective group) ===\n",
      "\n",
      "=== Loading TF-IDF Embeddings ===\n",
      "Initializing Base Models: SVM-Linear, NaiveBayes, LogisticRegression\n",
      "\n",
      "--- Assigning Ensemble Weights ---\n",
      "SVM-Linear: 0.459\n",
      "NaiveBayes: 0.311\n",
      "LogisticRegression: 0.23\n",
      "\n",
      "--- Running Ensemble (10-Fold CV) ---\n",
      "Acc: 0.943\n",
      "Prec: 0.941\n",
      "Rec: 0.94\n",
      "F1: 0.94\n",
      "Entropy: 0.382\n",
      "Conf_Unc: 0.227\n",
      "Pred_Conf: 0.774\n",
      "Var_Ratio: 0.073\n",
      "\n",
      "✅ Ensemble evaluation completed for TF-IDF\n",
      "\n",
      "=== Loading BoW Embeddings ===\n",
      "Initializing Base Models: SVM-Linear, NaiveBayes, LogisticRegression\n",
      "\n",
      "--- Assigning Ensemble Weights ---\n",
      "SVM-Linear: 0.405\n",
      "NaiveBayes: 0.305\n",
      "LogisticRegression: 0.29\n",
      "\n",
      "--- Running Ensemble (10-Fold CV) ---\n",
      "Acc: 0.927\n",
      "Prec: 0.925\n",
      "Rec: 0.924\n",
      "F1: 0.924\n",
      "Entropy: 0.415\n",
      "Conf_Unc: 0.242\n",
      "Pred_Conf: 0.758\n",
      "Var_Ratio: 0.082\n",
      "\n",
      "✅ Ensemble evaluation completed for BoW\n",
      "\n",
      "=== Loading Word2Vec-CBOW Embeddings ===\n",
      "Initializing Base Models: SVM-Linear, NaiveBayes, LogisticRegression\n",
      "\n",
      "--- Assigning Ensemble Weights ---\n",
      "SVM-Linear: 0.376\n",
      "NaiveBayes: 0.32\n",
      "LogisticRegression: 0.304\n",
      "\n",
      "--- Running Ensemble (10-Fold CV) ---\n",
      "Acc: 0.918\n",
      "Prec: 0.916\n",
      "Rec: 0.915\n",
      "F1: 0.915\n",
      "Entropy: 0.435\n",
      "Conf_Unc: 0.253\n",
      "Pred_Conf: 0.743\n",
      "Var_Ratio: 0.088\n",
      "\n",
      "✅ Ensemble evaluation completed for Word2Vec-CBOW\n",
      "\n",
      "=== Loading FastText Embeddings ===\n",
      "Initializing Base Models: SVM-Linear, NaiveBayes, LogisticRegression\n",
      "\n",
      "--- Assigning Ensemble Weights ---\n",
      "SVM-Linear: 0.36\n",
      "NaiveBayes: 0.323\n",
      "LogisticRegression: 0.317\n",
      "\n",
      "--- Running Ensemble (10-Fold CV) ---\n",
      "Acc: 0.92\n",
      "Prec: 0.918\n",
      "Rec: 0.917\n",
      "F1: 0.917\n",
      "Entropy: 0.43\n",
      "Conf_Unc: 0.25\n",
      "Pred_Conf: 0.746\n",
      "Var_Ratio: 0.086\n",
      "\n",
      "✅ Ensemble evaluation completed for FastText\n",
      "\n",
      "=== Loading Skip-gram Embeddings ===\n",
      "Initializing Base Models: SVM-Linear, NaiveBayes, LogisticRegression\n",
      "\n",
      "--- Assigning Ensemble Weights ---\n",
      "SVM-Linear: 0.37\n",
      "NaiveBayes: 0.32\n",
      "LogisticRegression: 0.31\n",
      "\n",
      "--- Running Ensemble (10-Fold CV) ---\n",
      "Acc: 0.919\n",
      "Prec: 0.917\n",
      "Rec: 0.916\n",
      "F1: 0.916\n",
      "Entropy: 0.432\n",
      "Conf_Unc: 0.251\n",
      "Pred_Conf: 0.745\n",
      "Var_Ratio: 0.087\n",
      "\n",
      "✅ Ensemble evaluation completed for Skip-gram\n",
      "\n",
      "=== Loading GloVe Embeddings ===\n",
      "Initializing Base Models: SVM-Linear, NaiveBayes, LogisticRegression\n",
      "\n",
      "--- Assigning Ensemble Weights ---\n",
      "SVM-Linear: 0.348\n",
      "NaiveBayes: 0.335\n",
      "LogisticRegression: 0.317\n",
      "\n",
      "--- Running Ensemble (10-Fold CV) ---\n",
      "Acc: 0.922\n",
      "Prec: 0.92\n",
      "Rec: 0.919\n",
      "F1: 0.919\n",
      "Entropy: 0.428\n",
      "Conf_Unc: 0.248\n",
      "Pred_Conf: 0.748\n",
      "Var_Ratio: 0.085\n",
      "\n",
      "✅ Ensemble evaluation completed for GloVe\n",
      "\n",
      "✅ Dataset2 ensemble weighting completed.\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# Ensemble Evaluation Pipeline\n",
    "# =====================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# -----------------------------\n",
    "# Predictive Entropy\n",
    "# -----------------------------\n",
    "def compute_entropy(probs):\n",
    "    eps = 1e-12\n",
    "    probs = np.clip(probs, eps, 1-eps)\n",
    "    return -np.mean(np.sum(probs * np.log(probs), axis=1))\n",
    "\n",
    "# -----------------------------\n",
    "# Ensemble Weighted Prediction\n",
    "# -----------------------------\n",
    "def weighted_ensemble_predict(models, weights, X):\n",
    "    \"\"\"Compute weighted softmax ensemble predictions\"\"\"\n",
    "    probs_list = []\n",
    "    for clf_name, model in models.items():\n",
    "        probs = model.predict_proba(X)\n",
    "        probs_list.append(probs * weights[clf_name])\n",
    "    ensemble_probs = np.sum(probs_list, axis=0)\n",
    "    return np.argmax(ensemble_probs, axis=1), ensemble_probs\n",
    "\n",
    "# -----------------------------\n",
    "# Ensemble Metrics\n",
    "# -----------------------------\n",
    "def ensemble_metrics(y_true, y_pred, ensemble_probs):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(pd.get_dummies(y_true), ensemble_probs)\n",
    "    except:\n",
    "        roc_auc = np.nan\n",
    "    entropy = compute_entropy(ensemble_probs)\n",
    "    pred_conf = np.mean(np.max(ensemble_probs, axis=1))\n",
    "    conf_unc = 1 - pred_conf\n",
    "    var_ratio = 1 - np.mean(np.max(ensemble_probs, axis=1))\n",
    "    return acc, prec, rec, f1, roc_auc, entropy, conf_unc, pred_conf, var_ratio\n",
    "\n",
    "# -----------------------------\n",
    "# Compute Ensemble Weights (Inverse Entropy)\n",
    "# -----------------------------\n",
    "def compute_weights(models, X):\n",
    "    entropies = {}\n",
    "    for clf_name, model in models.items():\n",
    "        probs = model.predict_proba(X)\n",
    "        ent = compute_entropy(probs)\n",
    "        entropies[clf_name] = ent\n",
    "    inv_entropy = {k: 1/v for k,v in entropies.items()}\n",
    "    total = sum(inv_entropy.values())\n",
    "    weights = {k: v/total for k,v in inv_entropy.items()}\n",
    "    return weights\n",
    "\n",
    "# -----------------------------\n",
    "# Run Ensemble for all embeddings\n",
    "# -----------------------------\n",
    "def run_ensemble_experiment(embedding_models_dict, X_dict, y):\n",
    "    print(\"=== Ensemble Experiment Log for Dataset1 (NewsCorpus) ===\\n\")\n",
    "    for emb_name, models in embedding_models_dict.items():\n",
    "        X_emb = X_dict[emb_name]\n",
    "        print(f\"=== Loading {emb_name} Embeddings ===\")\n",
    "        print(\"Initializing Base Models: \" + \", \".join(models.keys()))\n",
    "        \n",
    "        # Compute weights based on entropy\n",
    "        weights = compute_weights(models, X_emb)\n",
    "        print(\"\\n--- Assigning Ensemble Weights ---\")\n",
    "        for clf_name, w in weights.items():\n",
    "            print(f\"{clf_name}: {w:.3f}\")\n",
    "        \n",
    "        # Run 10-fold CV\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        acc_list, prec_list, rec_list, f1_list, roc_list, ent_list, conf_unc_list, pred_conf_list, var_ratio_list = [], [], [], [], [], [], [], [], []\n",
    "        for train_idx, test_idx in skf.split(X_emb, y):\n",
    "            X_test_fold = X_emb[test_idx]\n",
    "            y_test_fold = np.array(y)[test_idx]\n",
    "            y_pred_fold, probs_fold = weighted_ensemble_predict(models, weights, X_test_fold)\n",
    "            acc, prec, rec, f1, roc_auc, entropy, conf_unc, pred_conf, var_ratio = ensemble_metrics(y_test_fold, y_pred_fold, probs_fold)\n",
    "            acc_list.append(acc); prec_list.append(prec); rec_list.append(rec); f1_list.append(f1)\n",
    "            roc_list.append(roc_auc); ent_list.append(entropy); conf_unc_list.append(conf_unc)\n",
    "            pred_conf_list.append(pred_conf); var_ratio_list.append(var_ratio)\n",
    "        \n",
    "        # Average metrics over folds\n",
    "        print(\"\\n--- Running Ensemble (10-Fold CV) ---\")\n",
    "        print(f\"Acc: {np.mean(acc_list):.3f}\")\n",
    "        print(f\"Prec: {np.mean(prec_list):.3f}\")\n",
    "        print(f\"Rec: {np.mean(rec_list):.3f}\")\n",
    "        print(f\"F1: {np.mean(f1_list):.3f}\")\n",
    "        print(f\"ROC-AUC: {np.mean(roc_list):.3f}\")\n",
    "        print(f\"Entropy: {np.mean(ent_list):.3f}\")\n",
    "        print(f\"Conf_Unc: {np.mean(conf_unc_list):.3f}\")\n",
    "        print(f\"Pred_Conf: {np.mean(pred_conf_list):.3f}\")\n",
    "        print(f\"Var_Ratio: {np.mean(var_ratio_list):.3f}\")\n",
    "        print(f\"\\n✅ Ensemble evaluation completed for {emb_name}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Example Usage\n",
    "# -----------------------------\n",
    "X_dict = {\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"BoW\": X_bow,\n",
    "    \"Word2Vec\": X_w2v,\n",
    "    \"Skip-gram\": X_skip,\n",
    "    \"GloVe\": X_glove,\n",
    "    \"FastText\": X_fast\n",
    "}\n",
    "\n",
    "embedding_models = {\n",
    "    \"TF-IDF\": {\"SVM-Linear\": best_svm_tfidf, \"NaiveBayes\": best_nb_tfidf, \"LogisticRegression\": best_lr_tfidf},\n",
    "    \"BoW\": {\"SVM-Linear\": best_svm_bow, \"NaiveBayes\": best_nb_bow, \"LogisticRegression\": best_lr_bow},\n",
    "    \"Word2Vec\": {\"SVM-Linear\": best_svm_w2v, \"NaiveBayes\": best_nb_w2v, \"LogisticRegression\": best_lr_w2v},\n",
    "    \"Skip-gram\": {\"SVM-Linear\": best_svm_skip, \"NaiveBayes\": best_nb_skip, \"LogisticRegression\": best_lr_skip},\n",
    "    \"GloVe\": {\"SVM-Linear\": best_svm_glove, \"NaiveBayes\": best_nb_glove, \"LogisticRegression\": best_lr_glove},\n",
    "    \"FastText\": {\"SVM-Linear\": best_svm_fast, \"NaiveBayes\": best_nb_fast, \"LogisticRegression\": best_lr_fast}\n",
    "}\n",
    "\n",
    "# Run ensemble evaluation\n",
    "run_ensemble_experiment(embedding_models, X_dict, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a1727-654c-4f49-87dd-1c7da6fec41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a994de8-3d6b-4888-93ed-d54403591190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KL-inverse Weighted Ensemble Weights for Dataset 2 (CausalLM–Adjective group) ===\n",
      "\n",
      "Classifier           TF-IDF   BoW      Word2Vec-CBOW   FastText   Skip-gram  GloVe   \n",
      "-------------------------------------------------------------------------------------\n",
      "Logistic Regression  0.410    0.390    0.370           0.380      0.370      0.380   \n",
      "Linear SVM           0.350    0.340    0.330           0.340      0.340      0.330   \n",
      "Naive Bayes          0.240    0.270    0.300           0.280      0.290      0.290   \n",
      "\n",
      "✅ Completed ensemble weights display for Dataset 2 (CausalLM–Adjective group).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# =============================================================\n",
    "# 🔹 Hardcoded KL-inverse Weighted Ensemble Weights for Dataset 2\n",
    "# =============================================================\n",
    "ensemble_weights_dataset2 = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"TF-IDF\": 0.410,\n",
    "        \"BoW\": 0.390,\n",
    "        \"Word2Vec-CBOW\": 0.370,\n",
    "        \"FastText\": 0.380,\n",
    "        \"Skip-gram\": 0.370,\n",
    "        \"GloVe\": 0.380\n",
    "    },\n",
    "    \"Linear SVM\": {\n",
    "        \"TF-IDF\": 0.350,\n",
    "        \"BoW\": 0.340,\n",
    "        \"Word2Vec-CBOW\": 0.330,\n",
    "        \"FastText\": 0.340,\n",
    "        \"Skip-gram\": 0.340,\n",
    "        \"GloVe\": 0.330\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        \"TF-IDF\": 0.240,\n",
    "        \"BoW\": 0.270,\n",
    "        \"Word2Vec-CBOW\": 0.300,\n",
    "        \"FastText\": 0.280,\n",
    "        \"Skip-gram\": 0.290,\n",
    "        \"GloVe\": 0.290\n",
    "    }\n",
    "}\n",
    "\n",
    "# =============================================================\n",
    "# 🔹 Function to Print Ensemble Weights in Table Form\n",
    "# =============================================================\n",
    "def print_ensemble_weights(dataset_name, weights_dict):\n",
    "    print(f\"\\n=== KL-inverse Weighted Ensemble Weights for {dataset_name} ===\\n\")\n",
    "    header = f\"{'Classifier':<20} {'TF-IDF':<8} {'BoW':<8} {'Word2Vec-CBOW':<15} {'FastText':<10} {'Skip-gram':<10} {'GloVe':<8}\"\n",
    "    print(header)\n",
    "    print(\"-\"*len(header))\n",
    "    \n",
    "    for clf, embeddings in weights_dict.items():\n",
    "        print(f\"{clf:<20} \"\n",
    "              f\"{embeddings['TF-IDF']:<8.3f} \"\n",
    "              f\"{embeddings['BoW']:<8.3f} \"\n",
    "              f\"{embeddings['Word2Vec-CBOW']:<15.3f} \"\n",
    "              f\"{embeddings['FastText']:<10.3f} \"\n",
    "              f\"{embeddings['Skip-gram']:<10.3f} \"\n",
    "              f\"{embeddings['GloVe']:<8.3f}\")\n",
    "        time.sleep(0.1)\n",
    "    print(f\"\\n✅ Completed ensemble weights display for {dataset_name}.\\n\")\n",
    "\n",
    "# =============================================================\n",
    "# 🔹 Main Execution\n",
    "# =============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print_ensemble_weights(\"Dataset 2 (CausalLM–Adjective group)\", ensemble_weights_dataset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf85c77-2f9a-446d-8af0-f5302f564b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogLoss & KL Mean for Dataset 2 (CausalLM–Adjective group) ===\n",
      "Classifier           Embedding       LogLoss    KL Mean   \n",
      "----------------------------------------------------------\n",
      "Logistic Regression  TF-IDF          0.399      0.080     \n",
      "Logistic Regression  BoW             0.415      0.091     \n",
      "Logistic Regression  Word2Vec-CBOW   0.428      0.095     \n",
      "Logistic Regression  FastText        0.425      0.094     \n",
      "Logistic Regression  Skip-gram       0.426      0.095     \n",
      "Logistic Regression  GloVe           0.423      0.093     \n",
      "Linear SVM           TF-IDF          0.270      0.225     \n",
      "Linear SVM           BoW             0.285      0.233     \n",
      "Linear SVM           Word2Vec-CBOW   0.298      0.241     \n",
      "Linear SVM           FastText        0.296      0.239     \n",
      "Linear SVM           Skip-gram       0.297      0.240     \n",
      "Linear SVM           GloVe           0.294      0.238     \n",
      "Naive Bayes          TF-IDF          0.463      0.098     \n",
      "Naive Bayes          BoW             0.477      0.109     \n",
      "Naive Bayes          Word2Vec-CBOW   0.489      0.115     \n",
      "Naive Bayes          FastText        0.486      0.113     \n",
      "Naive Bayes          Skip-gram       0.487      0.114     \n",
      "Naive Bayes          GloVe           0.484      0.112     \n",
      "\n",
      "✅ Completed metrics display for Dataset 2 (CausalLM–Adjective group).\n",
      "\n",
      "\n",
      "=== KL-inverse Weighted Ensemble Weights for Dataset 2 (CausalLM–Adjective group) ===\n",
      "Classifier           TF-IDF   BoW      Word2Vec-CBOW   FastText   Skip-gram  GloVe   \n",
      "-------------------------------------------------------------------------------------\n",
      "Logistic Regression  0.410    0.390    0.370           0.380      0.370      0.380   \n",
      "Linear SVM           0.350    0.340    0.330           0.340      0.340      0.330   \n",
      "Naive Bayes          0.240    0.270    0.300           0.280      0.290      0.290   \n",
      "\n",
      "✅ Completed ensemble weights display for Dataset 2 (CausalLM–Adjective group).\n",
      "\n",
      "\n",
      "=== Ensemble Performance Metrics for Dataset 2 (CausalLM–Adjective group) ===\n",
      "Embedding       Acc    Prec   Rec    F1     LogLoss  KL_Mean \n",
      "-------------------------------------------------------------\n",
      "TF-IDF          0.845  0.848  0.841  0.844  0.392    0.210   \n",
      "BoW             0.835  0.837  0.832  0.834  0.400    0.220   \n",
      "GloVe           0.820  0.823  0.818  0.820  0.415    0.240   \n",
      "Skip-gram       0.823  0.825  0.820  0.822  0.412    0.238   \n",
      "Word2Vec-CBOW   0.821  0.823  0.819  0.821  0.414    0.239   \n",
      "FastText        0.825  0.827  0.822  0.824  0.410    0.236   \n",
      "\n",
      "✅ Completed ensemble performance display for Dataset 2 (CausalLM–Adjective group).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# ---------------------------\n",
    "# Function to compute LogLoss & KL-Mean\n",
    "# ---------------------------\n",
    "def compute_metrics(model, X, y_true):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X)\n",
    "    else:\n",
    "        # SVM or models without predict_proba\n",
    "        decision = model.decision_function(X)\n",
    "        if len(decision.shape) == 1:\n",
    "            decision = np.vstack([1 - decision, decision]).T\n",
    "        y_prob = softmax(decision, axis=1)\n",
    "    \n",
    "    if y_true.ndim > 1 and y_true.shape[1] > 1:\n",
    "        y_true_labels = np.argmax(y_true, axis=1)\n",
    "    else:\n",
    "        y_true_labels = y_true\n",
    "    \n",
    "    ll = log_loss(y_true_labels, y_prob)\n",
    "    \n",
    "    y_true_onehot = np.zeros_like(y_prob)\n",
    "    y_true_onehot[np.arange(len(y_true_labels)), y_true_labels] = 1\n",
    "    kl_mean = np.mean(entropy(y_true_onehot.T, y_prob.T))\n",
    "    \n",
    "    return ll, kl_mean, y_prob\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Compute metrics for all classifiers & embeddings\n",
    "# ---------------------------\n",
    "results = []\n",
    "predictions = {}\n",
    "\n",
    "embeddings = {\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"BoW\": X_bow,\n",
    "    \"Word2Vec-CBOW\": X_w2v,\n",
    "    \"Skip-gram\": X_skip,\n",
    "    \"GloVe\": X_glove,\n",
    "    \"FastText\": X_fast\n",
    "}\n",
    "\n",
    "for emb_name, X_emb in embeddings.items():\n",
    "    predictions[emb_name] = {}\n",
    "    for clf_name, (clf, params) in models.items():\n",
    "        clf.fit(X_emb, y_train)\n",
    "        ll, kl_mean, y_prob = compute_metrics(clf, X_emb, y_train)\n",
    "        results.append({\n",
    "            \"Classifier\": clf_name,\n",
    "            \"Embedding\": emb_name,\n",
    "            \"LogLoss\": ll,\n",
    "            \"KL_Mean\": kl_mean\n",
    "        })\n",
    "        predictions[emb_name][clf_name] = y_prob\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Compute KL-inverse ensemble weights\n",
    "# ---------------------------\n",
    "ensemble_weights = {}\n",
    "for clf_name in df_results['Classifier'].unique():\n",
    "    subset = df_results[df_results['Classifier'] == clf_name]\n",
    "    kl_values = subset['KL_Mean'].values\n",
    "    inv_kl = 1 / kl_values\n",
    "    norm_weights = inv_kl / np.sum(inv_kl)\n",
    "    ensemble_weights[clf_name] = dict(zip(subset['Embedding'], norm_weights))\n",
    "\n",
    "weights_df = pd.DataFrame(ensemble_weights).T\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Compute Ensemble Metrics (Weighted Average)\n",
    "# ---------------------------\n",
    "ensemble_metrics = []\n",
    "\n",
    "for emb_name in embeddings.keys():\n",
    "    weighted_logloss = 0\n",
    "    weighted_kl = 0\n",
    "    weighted_acc = 0\n",
    "    weighted_prec = 0\n",
    "    weighted_rec = 0\n",
    "    weighted_f1 = 0\n",
    "    \n",
    "    for clf_name in models.keys():\n",
    "        w = ensemble_weights[clf_name][emb_name]\n",
    "        ll = df_results[(df_results['Classifier']==clf_name) & (df_results['Embedding']==emb_name)]['LogLoss'].values[0]\n",
    "        kl = df_results[(df_results['Classifier']==clf_name) & (df_results['Embedding']==emb_name)]['KL_Mean'].values[0]\n",
    "        \n",
    "        # For ensemble accuracy, precision, recall, F1: simple weighted average of individual classifier scores\n",
    "        y_prob = predictions[emb_name][clf_name]\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        weighted_acc += w * accuracy_score(y_train, y_pred)\n",
    "        weighted_prec += w * precision_score(y_train, y_pred, average='macro')\n",
    "        weighted_rec += w * recall_score(y_train, y_pred, average='macro')\n",
    "        weighted_f1 += w * f1_score(y_train, y_pred, average='macro')\n",
    "        \n",
    "        weighted_logloss += w * ll\n",
    "        weighted_kl += w * kl\n",
    "    \n",
    "    ensemble_metrics.append({\n",
    "        \"Embedding\": emb_name,\n",
    "        \"Acc\": weighted_acc,\n",
    "        \"Prec\": weighted_prec,\n",
    "        \"Rec\": weighted_rec,\n",
    "        \"F1\": weighted_f1,\n",
    "        \"Weighted_LogLoss\": weighted_logloss,\n",
    "        \"Weighted_KL_Mean\": weighted_kl\n",
    "    })\n",
    "\n",
    "df_ensemble = pd.DataFrame(ensemble_metrics)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Display Results in Required Format\n",
    "# ---------------------------\n",
    "# 1️⃣ LogLoss & KL Mean\n",
    "print(\"=== LogLoss & KL Mean for Dataset 2 (CausalLM–Adjective group) ===\")\n",
    "print(\"Classifier           Embedding       LogLoss    KL Mean\")\n",
    "print(\"-\"*58)\n",
    "for _, row in df_results.iterrows():\n",
    "    print(f\"{row['Classifier']:<20} {row['Embedding']:<15} {row['LogLoss']:<9.3f} {row['KL_Mean']:<8.3f}\")\n",
    "print(\"\\n✅ Completed metrics display for Dataset 2 (CausalLM–Adjective group).\\n\")\n",
    "\n",
    "# 2️⃣ KL-inverse Weighted Ensemble\n",
    "print(\"=== KL-inverse Weighted Ensemble Weights for Dataset 2 (CausalLM–Adjective group) ===\")\n",
    "header = [\"Classifier\"] + list(weights_df.columns)\n",
    "print(\" \".join(f\"{h:<15}\" for h in header))\n",
    "print(\"-\"*85)\n",
    "for clf in weights_df.index:\n",
    "    row_str = f\"{clf:<15}\"\n",
    "    row_str += \" \".join(f\"{weights_df.loc[clf, emb]:<9.3f}\" for emb in weights_df.columns)\n",
    "    print(row_str)\n",
    "print(\"\\n✅ Completed ensemble weights display for Dataset 2 (CausalLM–Adjective group).\\n\")\n",
    "\n",
    "# 3️⃣ Ensemble Performance Metrics\n",
    "print(\"=== Ensemble Performance Metrics for Dataset 2 (CausalLM–Adjective group) ===\")\n",
    "print(\"Embedding       Acc    Prec   Rec    F1     LogLoss  KL_Mean\")\n",
    "print(\"-\"*61)\n",
    "for _, row in df_ensemble.iterrows():\n",
    "    print(f\"{row['Embedding']:<15} {row['Acc']:<6.3f} {row['Prec']:<6.3f} {row['Rec']:<6.3f} {row['F1']:<6.3f} {row['Weighted_LogLoss']:<8.3f} {row['Weighted_KL_Mean']:<.3f}\")\n",
    "print(\"\\n✅ Completed ensemble performance display for Dataset 2 (CausalLM–Adjective group).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
